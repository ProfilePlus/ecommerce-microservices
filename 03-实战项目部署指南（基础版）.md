# Java微服务全栈技术实战项目部署指南

## 项目概述

本项目是一个**电商订单管理系统**，涵盖从订单创建、库存扣减、消息通知到监控告警的完整链路。

### 技术栈清单
- **应用层**: Spring Boot 2.7+ / Spring Cloud Alibaba
- **数据库**: PostgreSQL 14 (主数据库)
- **缓存**: Redis 7.0 (缓存热点数据)
- **消息队列**: Kafka + RabbitMQ (异步解耦)
- **服务注册与配置**: Nacos 2.2 (服务发现、配置中心)
- **容器化**: Docker + Docker Compose
- **编排**: Kubernetes (K8s)
- **CI/CD**: Jenkins
- **监控**: Grafana + Prometheus + SkyWalking
- **API网关**: Spring Cloud Gateway

### 业务场景
```
用户下单 -> 订单服务(写PostgreSQL/Redis) 
         -> 发送Kafka消息 -> 库存服务消费(扣减库存)
         -> 发送RabbitMQ消息 -> 通知服务(发送通知)
         -> SkyWalking链路追踪
         -> Grafana实时监控
```

---

## 第一部分：基础环境准备

### 1.1 Linux虚拟机安装 (CentOS 7/Rocky Linux 9)

#### 1.1.1 使用VMware/VirtualBox创建虚拟机
```bash
# 推荐配置
CPU: 4核
内存: 8GB
硬盘: 100GB
网络: NAT模式 (可访问外网)
```

#### 1.1.2 下载CentOS镜像
- CentOS 7: https://www.centos.org/download/
- Rocky Linux 9: https://rockylinux.org/download

#### 1.1.3 基础系统配置
```bash
# 1. 更新系统
sudo yum update -y

# 2. 安装必要工具
sudo yum install -y vim wget curl git net-tools

# 3. 关闭防火墙(开发环境)
sudo systemctl stop firewalld
sudo systemctl disable firewalld

# 4. 关闭SELinux
sudo setenforce 0
sudo sed -i 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/selinux/config

# 5. 设置主机名
sudo hostnamectl set-hostname dev-server

# 6. 配置静态IP(可选)
sudo vi /etc/sysconfig/network-scripts/ifcfg-ens33
# 修改为静态IP
BOOTPROTO=static
IPADDR=192.168.xxx.xxx
NETMASK=255.255.255.0
GATEWAY=192.168.xxx.1
DNS1=8.8.8.8
```

#### 1.1.4 配置静态 IP（NAT 模式）

静态 IP 适用于需要固定虚拟机地址的场景（如服务部署、远程连接），以下是 NAT 模式下的配置方法（适配 CentOS 7 和 Rocky Linux 9）：

##### 1. 确认网络信息（必做）

先通过 DHCP 获取当前网络参数（作为静态配置参考）：

```bash
# 查看网卡名称、当前IP、子网掩码（关注带UP状态的网卡，如ens33/ens160）
ip addr show

# 查看网关地址（默认路由的via字段）
ip route show default
```

记录核心信息：

- 网卡名（如`ens33`、`ens160`）
- 网段（如`192.168.126.x`，从 IP 前三位判断）
- 网关（如`192.168.126.2`，NAT 模式通常为网段的`.2`）
- 子网掩码（默认`255.255.255.0`）

##### 2. 编辑网卡配置文件

配置文件路径：`/etc/sysconfig/network-scripts/ifcfg-<网卡名>`（替换为实际网卡名）

```bash
# 例如：网卡名为ens33时
sudo vi /etc/sysconfig/network-scripts/ifcfg-ens33
```

##### 3. 修改配置参数（替换为记录的信息）

```ini
TYPE=Ethernet
NAME=ens33           # 与网卡名一致
DEVICE=ens33         # 与网卡名一致
ONBOOT=yes           # 开机自动激活
BOOTPROTO=static     # 静态IP模式（替换dhcp）
IPADDR=192.168.126.100  # 静态IP（同网段未占用地址，如192.168.126.x）
NETMASK=255.255.255.0   # 子网掩码
GATEWAY=192.168.126.2   # 网关（与记录一致）
DNS1=114.114.114.114    # 国内通用DNS（可选：8.8.8.8、223.5.5.5）
```

保存退出（vi 中按`ESC`，输入`:wq`）。

##### 4. 重启网络服务（按系统版本选择）

```bash
# CentOS 7
sudo systemctl restart network

# Rocky Linux 9（使用NetworkManager）
sudo nmcli connection reload
sudo nmcli connection up ens33  # 替换为实际网卡名
```

##### 5. 验证配置

```bash
# 查看IP是否生效（应显示设置的静态IP，无dynamic标识）
ip addr show ens33

# 测试网络连通性
ping 192.168.126.2    # 测试网关
ping www.baidu.com    # 测试外网（依赖DNS）
```

##### 常见问题解决

- **IP 未生效**：检查`BOOTPROTO=static`和`ONBOOT=yes`是否正确，重新执行第 4 步。

- **无法上网**：确认`GATEWAY`与记录一致，更换`DNS1`为网关地址或公共 DNS。

- **IP 冲突**：更换静态 IP（如`192.168.126.101`），避免与网段内其他设备重复。

### 1.2 安装Java环境

```bash
# 方式1: 使用yum安装OpenJDK 11
sudo yum install -y java-11-openjdk java-11-openjdk-devel

# 方式2: 手动安装Oracle JDK (推荐JDK 11或17)
# 下载JDK tar.gz包后
sudo mkdir -p /usr/local/java
sudo tar -zxvf jdk-11.0.x_linux-x64_bin.tar.gz -C /usr/local/java

# 配置环境变量
sudo vi /etc/profile
# 添加以下内容
export JAVA_HOME=/usr/local/java/jdk-11.0.x
export PATH=$JAVA_HOME/bin:$PATH
export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar

# 使配置生效
source /etc/profile

# 验证安装
java -version
javac -version
```

### 1.3 安装Maven

```bash
# 下载Maven
cd /opt
sudo wget https://dlcdn.apache.org/maven/maven-3/3.9.5/binaries/apache-maven-3.9.5-bin.tar.gz

# 解压
sudo tar -zxvf apache-maven-3.9.5-bin.tar.gz

# 配置环境变量
sudo vi /etc/profile
export MAVEN_HOME=/opt/apache-maven-3.9.5
export PATH=$MAVEN_HOME/bin:$PATH

source /etc/profile

# 验证
mvn -version

# 配置Maven镜像(阿里云)
vi ~/.m2/settings.xml
```

```xml
<settings>
  <mirrors>
    <mirror>
      <id>aliyun</id>
      <mirrorOf>central</mirrorOf>
      <name>Aliyun Maven</name>
      <url>https://maven.aliyun.com/repository/public</url>
    </mirror>
  </mirrors>
</settings>
```

---

## 第二部分：Docker环境搭建

### 2.1 安装Docker

```bash
# 卸载旧版本
sudo yum remove docker docker-client docker-client-latest docker-common \
    docker-latest docker-latest-logrotate docker-logrotate docker-engine

# 安装依赖
sudo yum install -y yum-utils device-mapper-persistent-data lvm2

# 添加Docker仓库
sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo

# 或使用阿里云镜像
sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo

# 安装Docker
sudo yum install -y docker-ce docker-ce-cli containerd.io

# 启动Docker
sudo systemctl start docker
sudo systemctl enable docker

# 验证安装
docker --version
sudo docker run hello-world

# 配置Docker镜像加速(阿里云)
sudo mkdir -p /etc/docker
sudo tee /etc/docker/daemon.json <<-'EOF'
{
  "registry-mirrors": [
    "https://mirror.ccs.tencentyun.com",
    "https://docker.mirrors.ustc.edu.cn",
    "https://registry.docker-cn.com"
  ],
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "100m",
    "max-file": "3"
  }
}
EOF

sudo systemctl daemon-reload
sudo systemctl restart docker

# 将当前用户加入docker组(免sudo)
sudo usermod -aG docker $USER
newgrp docker
```

### 2.2 安装Docker Compose(旧版与新版 Docker Compose 的核心区别)

| 特性                 | 旧版（docker-compose）                                  | 新版（docker compose）                                       |
| -------------------- | ------------------------------------------------------- | ------------------------------------------------------------ |
| **名称与形式**       | 独立工具，命令为 `docker-compose`（带连字符）           | Docker 官方集成插件，命令为 `docker compose`（带空格）       |
| **版本标识**         | 版本号以 `1.x` 开头（如 1.29.2），已停止维护            | 版本号以 `2.x` 开头（如 2.27.0），持续更新                   |
| **与 Docker 的关系** | 独立发布，版本与 Docker 引擎不同步，易出现 API 兼容问题 | 与 Docker 引擎绑定发布，API 版本自动同步，无兼容问题         |
| **功能兼容性**       | 支持大部分基础功能，但不支持最新 Docker 特性            | 完全兼容旧版功能，同时支持 Docker 最新特性（如 BuildKit、扩展语法等） |
| **推荐场景**         | 仅兼容旧系统，不推荐新环境使用                          | 所有新环境首选，官方主推版本                                 |

#### 安装新版 Docker Compose（官方插件，推荐）

新版 `docker compose` 作为 Docker 官方插件，与 Docker 引擎深度集成，无需单独维护版本，彻底避免 API 兼容问题。

##### 1. 针对 Debian/Ubuntu 系统（apt 包管理器）

```bash
# 更新系统包索引
sudo apt-get update

# 安装docker-compose-plugin（与Docker引擎同步版本）
sudo apt-get install -y docker-compose-plugin
```

##### 2. 针对 CentOS/RHEL 系统（yum 包管理器）

```bash
# 更新系统包索引
sudo yum update -y

# 安装docker-compose-plugin
sudo yum install -y docker-compose-plugin
```

#### 验证安装

安装完成后，使用 **`docker compose`（带空格）** 命令验证版本（注意区别于旧版的 `docker-compose`）：

```bash
docker compose version
```

成功输出示例（版本号≥2.x 即为正常）：

```plaintext
Docker Compose version v2.27.0
```

#### 使用说明

- **命令形式**：所有操作通过 `docker compose`（空格分隔）完成，例如：

  ```bash
  # 启动服务（后台运行）
  docker compose up -d
  
  # 查看容器状态
  docker compose ps
  
  # 查看实时日志
  docker compose logs -f
  
  # 停止并删除容器（保留数据）
  docker compose down
  ```

- **配置文件兼容**：旧版 `docker-compose.yml` 配置文件可直接复用，无需修改。

- **与旧版的共存**：若系统中仍有旧版 `docker-compose`（带连字符），建议优先使用新版 `docker compose`（空格），避免因 API 版本差异导致的 “client version too old” 等错误。

### 总结

新版 `docker compose` 插件是官方主推的解决方案，通过与 Docker 引擎版本绑定，从根本上解决了旧版独立工具的 API 兼容问题。安装后只需使用 `docker compose`（空格）命令，即可稳定管理容器服务（如 Kafka、Zookeeper 等），推荐所有新环境优先采用。

### 2.3 虚拟机配置 Docker 镜像源（唯一可用：轩辕镜像）及问题解决

#### 2.3.1 国内 Docker 镜像源现状（核心结论）

当前国内可稳定使用的通用 Docker 镜像源已大幅收缩：

- **腾讯云（`https://mirror.ccs.tencentyun.com`）**、**阿里云（`https://xxx.mirror.aliyuncs.com`）**：仅限自家云服务器内使用，虚拟机等非云环境无法正常生效；
- **中科大源（`https://docker.mirrors.ustc.edu.cn`）**：已关闭服务，域名解析失败或无法访问；
- **唯一可用选择**：**轩辕镜像**（免费版`https://docker.xuanyuan.me`），支持虚拟机、物理机、NAS 等全场景，境内公司运营，通过 Cloudflare + 境内 CDN 加速，稳定性和通用性无替代方案。

#### 2.3.2 轩辕镜像配置步骤（必选方案）

1. **编辑 Docker 配置文件**直接写入轩辕镜像地址（确保 JSON 格式无语法错误，避免多余逗号）：

   ```bash
   sudo vi /etc/docker/daemon.json
   ```

   内容：

   ```json
   {
     "registry-mirrors": ["https://docker.xuanyuan.me"]
   }
   ```

2. **重启 Docker 使配置生效**

   ```bash
   sudo systemctl daemon-reload  # 重新加载配置
   sudo systemctl restart docker  # 重启Docker服务
   ```

3. **验证配置是否生效**执行命令检查，输出必须包含`https://docker.xuanyuan.me`：

   ```bash
   docker info | grep "Registry Mirrors" -A 1
   ```

4. **测试镜像拉取（核心验证）**拉取基础镜像确认加速生效：

   ```bash
   docker pull hello-world
   ```

   成功标志：显示拉取进度，最终提示 “Downloaded newer image”。

#### 2.3.3 关键问题解决（针对域名解析失败等核心报错）

1. **问题：`docker.xuanyuan.me`域名无法解析（`no such host`）**

   - 原因：本地 DNS 服务器未正确解析轩辕镜像域名（常见于部分局域网 DNS 限制）。

   - 解决：

     ① 配置可靠 DNS（优先阿里云 / 腾讯云公共 DNS）：

     ```bash
     sudo vi /etc/resolv.conf
     # 添加：
     nameserver 223.5.5.5  # 阿里云DNS
     nameserver 119.29.29.29  # 腾讯云DNS
     ```

     ② 手动绑定 IP（若 DNS 仍解析失败，通过宿主机查询 IP 后绑定）：

     - 宿主机执行`nslookup docker.xuanyuan.me`获取 IP（如`103.xxx.xxx.xxx`）；
     - 虚拟机绑定：

     ```bash
     sudo vi /etc/hosts
     # 添加（替换为实际IP）：
     103.xxx.xxx.xxx  docker.xuanyuan.me
     ```

2. **问题：配置后仍直连 Docker Hub（`registry-1.docker.io`）**

   - 原因：Docker 缓存旧配置未刷新，未读取新镜像源。
   - 解决：清除缓存并重启 Docker：

   ```bash
   sudo systemctl stop docker
   sudo rm -rf /var/lib/docker/network/files/  # 清除网络缓存
   sudo systemctl start docker
   ```

3. **问题：拉取超时（`context deadline exceeded`）**

   - 原因：网络连通性差或 CDN 节点暂时不可用。
   - 解决：测试轩辕镜像服务可达性，切换网络环境：

   ```bash
   curl -I https://docker.xuanyuan.me/v2/  # 正常应返回401 Unauthorized（服务在线）
   ```

   若超时，将宿主机切换至手机热点（避开局域网限制）后重试。

​       通过以上配置和问题解决步骤，可确保虚拟机在国内网络环境下稳定使用 Docker，轩辕镜像是当前唯一通用且可靠的选择。

### 2.4 虚拟机访问 GitHub 报错及解决方案

虚拟机访问 GitHub 时常见报错包括 “连接超时（context deadline exceeded）”“无法连接 443 端口（Failed to connect to [github.com](https://github.com/) port 443）” 等，多因网络限制或代理配置问题，解决方案如下：

#### 2.4.1 核心问题分析

- 国内网络对 GitHub 的直接访问限制；
- 主机科学上网工具未在虚拟机中生效（虚拟机与主机网络隔离）；
- Docker 服务未配置代理（不继承系统代理）；
- `sudo`命令清除代理环境变量（导致带权限的命令无法使用代理）。

#### 2.4.2 解决方案步骤

1. **通过主机科学上网工具共享代理**确保主机科学上网工具（如 Clash）开启 “允许局域网访问”，并获取主机在虚拟机网段的 IP（NAT 模式通常为`192.168.126.1`）和代理端口（如 Clash 默认`socks5://192.168.126.1:7898`）。

2. **配置虚拟机系统级代理**在虚拟机中设置代理环境变量，让`curl`、`wget`等工具走代理：

   ```bash
   # 临时生效（当前终端）
   export all_proxy=socks5://192.168.126.1:7898  # 替换为主机IP和代理端口
   export http_proxy=$all_proxy
   export https_proxy=$all_proxy
   
   # 永久生效（所有终端）
   sudo vi /etc/profile
   # 添加上述export命令，保存后生效：
   source /etc/profile
   ```

3. **为 Docker 单独配置代理**Docker 不继承系统代理，需单独配置：

   ```bash
   # 创建Docker代理配置目录
   sudo mkdir -p /etc/systemd/system/docker.service.d
   # 编辑代理配置文件
   sudo vi /etc/systemd/system/docker.service.d/proxy.conf
   # 添加内容（替换为主机IP和代理端口）：
   [Service]
   Environment="HTTP_PROXY=socks5://192.168.126.1:7898"
   Environment="HTTPS_PROXY=socks5://192.168.126.1:7898"
   Environment="NO_PROXY=localhost,127.0.0.1"
   
   # 重启Docker使配置生效
   sudo systemctl daemon-reload
   sudo systemctl restart docker
   ```

4. **解决 sudo 命令代理失效问题**`sudo`默认清除环境变量，需用`-E`参数保留代理配置：

   ```bash
   # 用sudo -E执行需要权限的命令（如下载docker-compose）
   sudo -E curl -L "https://github.com/docker/compose/releases/download/v2.23.0/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
   ```

5. **验证访问有效性**

   ```bash
   # 测试系统代理（应返回HTTP/2 200）
   curl -I https://github.com
   
   # 测试Docker代理（应成功拉取镜像）
   docker run --rm curlimages/curl -I https://github.com
   ```

## 第三部分：中间件部署（Docker方式）

### 3.1 PostgreSQL 数据库

```bash
# 创建工作目录
mkdir -p ~/docker-env/postgres/data

# 运行PostgreSQL容器
docker run -d \
  --name postgres \
  -e POSTGRES_USER=admin \
  -e POSTGRES_PASSWORD=Admin@123 \
  -e POSTGRES_DB=order_db \
  -p 5432:5432 \
  -v ~/docker-env/postgres/data:/var/lib/postgresql/data \
  --restart=always \
  postgres:14-alpine

# 验证运行
docker ps | grep postgres

# 连接数据库测试
docker exec -it postgres psql -U admin -d order_db

# 在PostgreSQL中执行
\l          # 查看数据库
\dt         # 查看表
\q          # 退出
```

#### 初始化数据库脚本

```bash
# 创建数据库初始化脚本
cat > ~/docker-env/postgres/init.sql <<'EOF'
-- 创建订单表
CREATE TABLE t_order (
    id BIGSERIAL PRIMARY KEY,
    order_no VARCHAR(64) NOT NULL UNIQUE,
    user_id BIGINT NOT NULL,
    product_id BIGINT NOT NULL,
    product_name VARCHAR(255),
    quantity INT NOT NULL,
    total_amount DECIMAL(10,2),
    status VARCHAR(20) DEFAULT 'PENDING',
    create_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    update_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 创建库存表
CREATE TABLE t_inventory (
    id BIGSERIAL PRIMARY KEY,
    product_id BIGINT NOT NULL UNIQUE,
    product_name VARCHAR(255),
    stock INT NOT NULL,
    version INT DEFAULT 0,
    update_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 插入测试数据
INSERT INTO t_inventory (product_id, product_name, stock) VALUES
(1001, 'iPhone 15 Pro', 100),
(1002, '华为Mate 60', 200),
(1003, '小米14 Ultra', 150);

-- 创建索引
CREATE INDEX idx_order_no ON t_order(order_no);
CREATE INDEX idx_user_id ON t_order(user_id);
CREATE INDEX idx_product_id ON t_inventory(product_id);
EOF

# 导入初始化脚本
docker cp ~/docker-env/postgres/init.sql postgres:/tmp/
docker exec -it postgres psql -U admin -d order_db -f /tmp/init.sql
```

#### 3.1.1 PostgreSQL 常用操作命令

初始化完成后，可再次连接数据库进行日常操作：

```bash
# 重新连接数据库
docker exec -it postgres psql -U admin -d order_db
```

在 psql 交互式环境中，可执行以下常用命令：

1. **切换数据库**（若需操作其他数据库）

   ```sql
   \c 目标数据库名 用户名  # 示例：切换到order_db（当前已连接，仅作演示）
   \c order_db admin
   ```

2. **查看表结构**

   ```sql
   \d 表名  # 查看表基本结构（字段、类型、约束等）
   \d t_order  # 查看订单表结构
   \d t_inventory  # 查看库存表结构
   
   \d+ 表名  # 查看表详细信息（含存储大小、描述等）
   \d+ t_order
   ```
   
3. **查询表数据**

   ```sql
   -- 查询表中所有数据（示例：查询库存表所有记录）
   SELECT * FROM t_inventory;
   
   -- 条件查询（示例：查询库存大于150的商品）
   SELECT product_id, product_name, stock FROM t_inventory WHERE stock > 150;
   
   -- 分页查询（示例：查询订单表前10条记录，按创建时间倒序）
   SELECT * FROM t_order ORDER BY create_time DESC LIMIT 10 OFFSET 0;
   ```
   
4. **插入数据**（示例：新增一条订单记录）

   ```sql
   INSERT INTO t_order (order_no, user_id, product_id, product_name, quantity, total_amount, status)
   VALUES ('ORD20251116001', 10001, 1001, 'iPhone 15 Pro', 2, 19998.00, 'PAID');
   ```
   
5. **更新数据**（示例：修改库存表中商品的库存数量）

   ```sql
UPDATE t_inventory 
   SET stock = stock - 2, update_time = CURRENT_TIMESTAMP 
WHERE product_id = 1001;
   ```

6. **删除数据**（谨慎操作，示例：删除指定订单）

   ```sql
DELETE FROM t_order WHERE order_no = 'ORD20251116001';
   ```

7. **查看索引**（示例：查看 t_order 表的索引）

   ```sql
   \di idx_order_no  # 查看指定索引详情
   \di+ t_order  # 查看表关联的所有索引
   ```
   
8. **查看用户与权限**

   ```sql
   \du  # 查看所有数据库用户
   \du+ admin  # 查看admin用户的详细权限
   ```
   
9. **查看当前连接信息**

   ```sql
\conninfo  # 显示当前连接的数据库、用户、端口等信息
   ```

10. **执行外部 SQL 脚本**（若需再次导入脚本）

    ```sql
    \i /tmp/新脚本.sql  # 执行容器内/tmp目录下的SQL脚本
    ```


> 说明：
>
> - 以`\`开头的为 psql 元命令（如`\d`、`\c`），无需加分号结尾；
> - SQL 语句（如`SELECT`、`INSERT`）需以分号`;`结尾才会执行；
> - 操作前建议用`\dt`确认表存在，避免因表名错误导致失败。

### 3.2 Redis 缓存

```bash
# 创建Redis配置目录
mkdir -p ~/docker-env/redis/conf
mkdir -p ~/docker-env/redis/data

# 创建Redis配置文件
cat > ~/docker-env/redis/conf/redis.conf <<'EOF'
# 基础配置
bind 0.0.0.0
port 6379
protected-mode no
daemonize no
# 密码配置
requirepass redis  # 例如设置密码为 redis

# 持久化
appendonly yes
appendfilename "appendonly.aof"
save 900 1
save 300 10
save 60 10000

# 内存管理
maxmemory 256mb
maxmemory-policy allkeys-lru

# 日志
loglevel notice
EOF

# 运行Redis容器
docker run -d \
  --name redis \
  -p 6379:6379 \
  -v ~/docker-env/redis/conf/redis.conf:/etc/redis/redis.conf \
  -v ~/docker-env/redis/data:/data \
  --restart=always \
  redis:7.0-alpine redis-server /etc/redis/redis.conf

# 验证
docker exec -it redis redis-cli -a redis ping
# 应返回 PONG

# 测试Redis操作
docker exec -it redis redis-cli -a redis
# 执行Redis命令
set test "Hello Redis"
get test
keys *
exit
```

### 3.3 Kafka 消息队列

```bash
# 创建Kafka工作目录
mkdir -p ~/docker-env/kafka

# 创建docker-compose文件
cat > ~/docker-env/kafka/docker-compose.yml <<'EOF'
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    volumes:
      - ~/docker-env/kafka/zk-data:/var/lib/zookeeper/data
      - ~/docker-env/kafka/zk-logs:/var/lib/zookeeper/log

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "9093:9093"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT_INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
    volumes:
      - ~/docker-env/kafka/kafka-data:/var/lib/kafka/data
EOF

# 启动Kafka
cd ~/docker-env/kafka
docker-compose up -d

# 验证
docker ps | grep kafka

# 创建测试Topic
docker exec -it kafka kafka-topics --create \
  --bootstrap-server localhost:9093 \
  --topic order-created \
  --partitions 3 \
  --replication-factor 1

docker exec -it kafka kafka-topics --create \
  --bootstrap-server localhost:9093 \
  --topic inventory-updated \
  --partitions 3 \
  --replication-factor 1

# 查看Topic列表
docker exec -it kafka kafka-topics --list --bootstrap-server localhost:9093
```

### 3.4 RabbitMQ 消息队列

```bash
# 运行RabbitMQ (带管理界面)
docker run -d \
  --name rabbitmq \
  -p 5672:5672 \
  -p 15672:15672 \
  -e RABBITMQ_DEFAULT_USER=admin \
  -e RABBITMQ_DEFAULT_PASS=Admin@123 \
  -v ~/docker-env/rabbitmq/data:/var/lib/rabbitmq \
  --restart=always \
  rabbitmq:3.12-management-alpine

# 等待启动完成
sleep 30

# 访问管理界面
# 浏览器打开: http://虚拟机IP:15672
# 用户名: admin  密码: Admin@123

# 验证
docker exec -it rabbitmq rabbitmqctl status

# 创建交换机和队列 (通过Web界面或命令)
docker exec -it rabbitmq rabbitmqadmin -u admin -p Admin@123 declare exchange \
  name=order.exchange type=topic durable=true

docker exec -it rabbitmq rabbitmqadmin -u admin -p Admin@123 declare queue \
  name=notification.queue durable=true
```

### 3.5 Nacos 服务注册与配置中心

```bash
# 创建Nacos目录
mkdir -p ~/docker-env/nacos/logs

# 运行Nacos (单机模式)
docker run -d \
  --name nacos \
  -e MODE=standalone \
  -p 8848:8848 \
  -p 9848:9848 \
  -p 9849:9849 \
  -v ~/docker-env/nacos/logs:/home/nacos/logs \
  --restart=always \
  nacos/nacos-server:v2.2.3

# 等待启动
sleep 40

# 访问Nacos控制台
# 浏览器: http://虚拟机IP:8848/nacos
# 用户名/密码: nacos/nacos

# 验证
curl http://localhost:8848/nacos/v1/console/health/liveness
```

Nacos 有两种数据存储模式：

- **单机模式**：默认使用嵌入式 Derby 数据库（无需额外配置，开箱即用），但需通过 `MODE=standalone` 明确指定单机模式，否则会默认尝试集群模式。
- **集群模式**：必须依赖外部数据库（如 MySQL），需手动配置数据库连接信息（URL、用户名、密码等），否则会因找不到数据源启动失败。

### 3.6 Prometheus + Grafana 监控

```bash
# 创建监控目录
mkdir -p ~/docker-env/monitor/{prometheus,grafana}

# 创建Prometheus配置
cat > ~/docker-env/monitor/prometheus/prometheus.yml <<'EOF'
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9091']
  
  - job_name: 'order-service'
    metrics_path: '/actuator/prometheus'
    static_configs:
      - targets: ['host.docker.internal:8081']
  
  - job_name: 'inventory-service'
    metrics_path: '/actuator/prometheus'
    static_configs:
      - targets: ['host.docker.internal:8082']
  
  - job_name: 'notification-service'
    metrics_path: '/actuator/prometheus'
    static_configs:
      - targets: ['host.docker.internal:8083']
EOF

# 创建监控docker-compose
cat > ~/docker-env/monitor/docker-compose.yml <<'EOF'
services:
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "9091:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./prometheus/data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
    restart: always
    extra_hosts:
      - "host.docker.internal:host-gateway"

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=Admin@123
    volumes:
      - ./grafana/data:/var/lib/grafana
    restart: always
    depends_on:
      - prometheus
EOF

cd ~/docker-env/monitor
# 为挂载目录赋权
chmod 777 -R grafana/
chmod 777 -R prometheus/
# 启动监控服务
docker compose up -d

# 访问Grafana
# 浏览器: http://虚拟机IP:3000
# 用户名/密码: admin/Admin@123
```

##### 什么是 Cockpit？

Prometheus默认端口应为9090，但是Centos10 stream的**`cockpit`** 服务默认端口也是9090，所以此处Prometheus的默认端口修改为9091。

Cockpit 是一个开源的 Linux 服务器 Web 管理工具，默认使用 `9090` 端口提供图形化管理界面（方便通过浏览器管理服务器）。如果你的服务器不需要这个工具，可以停止它以释放 `9090` 端口；如果需要保留，则继续使用之前修改的 `9091` 端口即可。

### 3.7 SkyWalking APM 链路追踪

```bash
# 创建SkyWalking目录
mkdir -p ~/docker-env/skywalking

# 创建docker-compose
cat > ~/docker-env/skywalking/docker-compose.yml <<'EOF'
services:
  elasticsearch:
    image: elasticsearch:7.17.15
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"  # 限制内存，避免资源不足
    ports:
      - "9200:9200"
    volumes:
      - ./es-data:/usr/share/elasticsearch/data
    healthcheck:  # 关键：添加健康检查，确保ES就绪
      test: ["CMD", "curl", "-f", "http://localhost:9200"]  # 检查ES是否响应
      interval: 10s  # 每10秒检查一次
      timeout: 5s    # 超时时间5秒
      retries: 5     # 最多重试5次（总等待约50秒）

  oap:
    image: apache/skywalking-oap-server:9.6.0
    container_name: skywalking-oap
    depends_on:
      elasticsearch:
        condition: service_healthy  # 关键：等待ES健康检查通过后再启动OAP
    environment:
      SW_STORAGE: elasticsearch
      SW_STORAGE_ES_CLUSTER_NODES: elasticsearch:9200  # 连接ES的地址（服务名+端口）
      SW_ES_VERSION: 7  # 关键：明确指定ES版本为7.x，避免协议兼容问题
      JAVA_OPTS: "-Xms512m -Xmx512m"  # 限制OAP内存，避免资源不足
    ports:
      - "11800:11800"
      - "12800:12800"

  ui:
    image: apache/skywalking-ui:9.6.0
    container_name: skywalking-ui
    depends_on:
      - oap  # 等待OAP启动后再启动UI
    environment:
      SW_OAP_ADDRESS: http://oap:12800  # 连接OAP的地址（服务名+端口）
    ports:
      - "8080:8080"
EOF

cd ~/docker-env/skywalking
# 挂载目录赋权
chmod 777 -R es-data/
# 启动SkyWalking
docker compose up -d

# 等待启动(需要较长时间)
sleep 60

# 访问SkyWalking UI
# 浏览器: http://虚拟机IP:8080

# 下载SkyWalking Agent (用于Java应用)
cd ~/docker-env/skywalking
wget https://archive.apache.org/dist/skywalking/java-agent/9.0.0/apache-skywalking-java-agent-9.0.0.tgz
tar -zxvf apache-skywalking-java-agent-9.0.0.tgz
```

##### 补充：

OAP 服务出现连接问题（启动后退出、无法连接 Elasticsearch）的核心原因可总结为以下三点：

1. **启动顺序与就绪状态不同步**Elasticsearch 启动需要初始化（加载数据、建立索引等），耗时较长；而 OAP 启动速度快，默认配置下会在 Elasticsearch 还未完全就绪（9200 端口未响应）时就尝试连接，导致首次连接失败（`Connection refused`）。Docker Compose 默认的 `depends_on` 仅检查容器是否启动，不验证服务是否真正可用，进一步加剧了这个问题。
2. **Elasticsearch 版本兼容未明确**SkyWalking OAP 与 Elasticsearch 存在版本依赖（例如 OAP 9.6.0 需明确适配 ES 7.x 或 8.x），但初始配置中未指定 `SW_ES_VERSION=7`，导致 OAP 可能使用不兼容的协议连接 ES 7.17.15，最终连接失败。
3. **网络连通性验证不足**虽然 Elasticsearch 和 OAP 在同一 Docker 网络，但初期未通过健康检查或临时容器验证网络互通性，一度无法排除 “服务名解析失败”“端口被拦截” 等潜在网络问题（后续验证确认网络正常，但配置缺陷掩盖了核心问题）。

通过补充 **健康检查依赖**（确保 OAP 在 ES 就绪后启动）、明确 **ES 版本配置**（`SW_ES_VERSION=7`），最终解决了连接问题。核心是让 OAP 在 “正确的时间” 用 “正确的协议” 连接 “已就绪的 ES 服务”


---



## 第四部分：Java微服务开发

### 4.1 项目结构

```
ecommerce-microservices/
├── order-service/          # 订单服务
├── inventory-service/      # 库存服务
├── notification-service/   # 通知服务
├── gateway-service/        # API网关
└── common/                 # 公共模块
```

### 4.2 父POM配置

创建父项目 `ecommerce-microservices`

```xml
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 
         http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>

    <groupId>com.demo</groupId>
    <artifactId>ecommerce-microservices</artifactId>
    <version>1.0.0</version>
    <packaging>pom</packaging>

    <modules>
        <module>common</module>
        <module>order-service</module>
        <module>inventory-service</module>
        <module>notification-service</module>
        <module>gateway-service</module>
    </modules>

    <properties>
        <java.version>1.8</java.version>
        <spring-boot.version>2.7.17</spring-boot.version>
        <spring-cloud.version>2021.0.8</spring-cloud.version>
        <spring-cloud-alibaba.version>2021.0.5.0</spring-cloud-alibaba.version>
        <maven.compiler.source>1.8</maven.compiler.source>
        <maven.compiler.target>1.8</maven.compiler.target>
        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
    </properties>

    <dependencyManagement>
        <dependencies>
            <!-- Spring Boot -->
            <dependency>
                <groupId>org.springframework.boot</groupId>
                <artifactId>spring-boot-dependencies</artifactId>
                <version>${spring-boot.version}</version>
                <type>pom</type>
                <scope>import</scope>
            </dependency>

            <!-- Spring Cloud -->
            <dependency>
                <groupId>org.springframework.cloud</groupId>
                <artifactId>spring-cloud-dependencies</artifactId>
                <version>${spring-cloud.version}</version>
                <type>pom</type>
                <scope>import</scope>
            </dependency>

            <!-- Spring Cloud Alibaba -->
            <dependency>
                <groupId>com.alibaba.cloud</groupId>
                <artifactId>spring-cloud-alibaba-dependencies</artifactId>
                <version>${spring-cloud-alibaba.version}</version>
                <type>pom</type>
                <scope>import</scope>
            </dependency>
        </dependencies>
    </dependencyManagement>

    <build>
        <plugins>
            <plugin>
                <groupId>org.springframework.boot</groupId>
                <artifactId>spring-boot-maven-plugin</artifactId>
                <version>${spring-boot.version}</version>
            </plugin>
        </plugins>
    </build>
</project>
```

### 4.3 订单服务 (order-service)

#### pom.xml

```xml
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 
         http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <parent>
        <groupId>com.demo</groupId>
        <artifactId>ecommerce-microservices</artifactId>
        <version>1.0.0</version>
    </parent>
    <modelVersion>4.0.0</modelVersion>
    <artifactId>order-service</artifactId>

    <dependencies>
        <!-- Spring Boot Web -->
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-web</artifactId>
        </dependency>

        <!-- Spring Data JPA -->
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-data-jpa</artifactId>
        </dependency>

        <!-- PostgreSQL Driver -->
        <dependency>
            <groupId>org.postgresql</groupId>
            <artifactId>postgresql</artifactId>
        </dependency>

        <!-- Redis -->
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-data-redis</artifactId>
        </dependency>

        <!-- Kafka -->
        <dependency>
            <groupId>org.springframework.kafka</groupId>
            <artifactId>spring-kafka</artifactId>
        </dependency>

        <!-- Nacos Discovery -->
        <dependency>
            <groupId>com.alibaba.cloud</groupId>
            <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>
        </dependency>

        <!-- Nacos Config -->
        <dependency>
            <groupId>com.alibaba.cloud</groupId>
            <artifactId>spring-cloud-starter-alibaba-nacos-config</artifactId>
        </dependency>

        <!-- Actuator (监控) -->
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-actuator</artifactId>
        </dependency>

        <!-- Micrometer Prometheus -->
        <dependency>
            <groupId>io.micrometer</groupId>
            <artifactId>micrometer-registry-prometheus</artifactId>
        </dependency>

        <!-- Lombok -->
        <dependency>
            <groupId>org.projectlombok</groupId>
            <artifactId>lombok</artifactId>
        </dependency>
    </dependencies>
</project>
```

#### bootstrap.yml（Nacos配置中心需要）

```yaml
spring:
  application:
    name: order-service
  cloud:
    nacos:
      config:
        server-addr: 192.168.xxx.xxx:8848
        file-extension: yaml
        namespace: public
      discovery:
        server-addr: 192.168.xxx.xxx:8848
```

#### application.yml

```yaml
server:
  port: 8081

spring:
  application:
    name: order-service
  
  # PostgreSQL配置
  datasource:
    url: jdbc:postgresql://192.168.xxx.xxx:5432/order_db
    username: admin
    password: Admin@123
    driver-class-name: org.postgresql.Driver
  
  jpa:
    hibernate:
      ddl-auto: update
    show-sql: true
    properties:
      hibernate:
        dialect: org.hibernate.dialect.PostgreSQLDialect
        format_sql: true
  
  # Redis配置
  redis:
    host: 192.168.xxx.xxx
    port: 6379
    password: redis
    database: 0
    timeout: 3000ms
    lettuce:
      pool:
        max-active: 8
        max-idle: 8
        min-idle: 0
  
  # Kafka配置
  kafka:
    bootstrap-servers: 192.168.xxx.xxx:9092
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer
      acks: 1
      retries: 3
  

# Actuator监控配置
management:
  endpoints:
    web:
      exposure:
        include: '*'
  metrics:
    export:
      prometheus:
        enabled: true
```

#### OrderController.java

```java
package com.demo.order.controller;

import com.demo.order.dto.OrderRequest;
import com.demo.order.dto.OrderResponse;
import com.demo.order.service.OrderService;
import lombok.RequiredArgsConstructor;
import org.springframework.web.bind.annotation.*;

import java.util.List;

@RestController
@RequestMapping("/api/orders")
@RequiredArgsConstructor
public class OrderController {
    
    private final OrderService orderService;
    
    /**
     * 创建订单
     */
    @PostMapping
    public OrderResponse createOrder(@RequestBody OrderRequest request) {
        return orderService.createOrder(request);
    }
    
    /**
     * 查询订单
     */
    @GetMapping("/{orderNo}")
    public OrderResponse getOrder(@PathVariable String orderNo) {
        return orderService.getOrder(orderNo);
    }
    
    /**
     * 查询用户订单列表
     */
    @GetMapping("/user/{userId}")
    public List<OrderResponse> getUserOrders(@PathVariable Long userId) {
        return orderService.getUserOrders(userId);
    }
    
    /**
     * 健康检查
     */
    @GetMapping("/health")
    public String health() {
        return "Order Service is running!";
    }
}
```

#### OrderService.java

```java
package com.demo.order.service;

import com.demo.order.dto.OrderRequest;
import com.demo.order.dto.OrderResponse;
import com.demo.order.entity.Order;
import com.demo.order.repository.OrderRepository;
import com.fasterxml.jackson.databind.ObjectMapper;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.data.redis.core.StringRedisTemplate;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.stereotype.Service;
import org.springframework.transaction.annotation.Transactional;

import java.math.BigDecimal;
import java.time.LocalDateTime;
import java.util.List;
import java.util.UUID;
import java.util.concurrent.TimeUnit;
import java.util.stream.Collectors;

@Slf4j
@Service
@RequiredArgsConstructor
public class OrderService {
    
    private final OrderRepository orderRepository;
    private final KafkaTemplate<String, Object> kafkaTemplate;
    private final StringRedisTemplate redisTemplate;
    private final ObjectMapper objectMapper;
    
    private static final String ORDER_CACHE_PREFIX = "order:";
    private static final String TOPIC_ORDER_CREATED = "order-created";
    
    /**
     * 创建订单
     */
    @Transactional
    public OrderResponse createOrder(OrderRequest request) {
        log.info("创建订单: userId={}, productId={}", request.getUserId(), request.getProductId());
        
        // 1. 生成订单号
        String orderNo = generateOrderNo();
        
        // 2. 创建订单
        Order order = new Order();
        order.setOrderNo(orderNo);
        order.setUserId(request.getUserId());
        order.setProductId(request.getProductId());
        order.setProductName(request.getProductName());
        order.setQuantity(request.getQuantity());
        order.setTotalAmount(request.getTotalAmount());
        order.setStatus("PENDING");
        order.setCreateTime(LocalDateTime.now());
        order.setUpdateTime(LocalDateTime.now());
        
        Order savedOrder = orderRepository.save(order);
        
        // 3. 缓存订单到Redis (30分钟)
        try {
            String cacheKey = ORDER_CACHE_PREFIX + orderNo;
            String orderJson = objectMapper.writeValueAsString(savedOrder);
            redisTemplate.opsForValue().set(cacheKey, orderJson, 30, TimeUnit.MINUTES);
            log.info("订单已缓存到Redis: {}", orderNo);
        } catch (Exception e) {
            log.error("缓存订单失败", e);
        }
        
        // 4. 发送Kafka消息
        try {
            kafkaTemplate.send(TOPIC_ORDER_CREATED, orderNo, savedOrder);
            log.info("订单创建消息已发送到Kafka: {}", orderNo);
        } catch (Exception e) {
            log.error("发送Kafka消息失败", e);
        }
        
        return toResponse(savedOrder);
    }
    
    /**
     * 查询订单 (先查Redis,再查数据库)
     */
    public OrderResponse getOrder(String orderNo) {
        log.info("查询订单: {}", orderNo);
        
        // 1. 先从Redis查询
        String cacheKey = ORDER_CACHE_PREFIX + orderNo;
        try {
            String cachedOrder = redisTemplate.opsForValue().get(cacheKey);
            if (cachedOrder != null) {
                log.info("从Redis缓存获取订单: {}", orderNo);
                Order order = objectMapper.readValue(cachedOrder, Order.class);
                return toResponse(order);
            }
        } catch (Exception e) {
            log.error("从Redis读取失败", e);
        }
        
        // 2. Redis中没有,从数据库查询
        Order order = orderRepository.findByOrderNo(orderNo)
                .orElseThrow(() -> new RuntimeException("订单不存在: " + orderNo));
        
        // 3. 写回Redis
        try {
            String orderJson = objectMapper.writeValueAsString(order);
            redisTemplate.opsForValue().set(cacheKey, orderJson, 30, TimeUnit.MINUTES);
        } catch (Exception e) {
            log.error("写入Redis失败", e);
        }
        
        return toResponse(order);
    }
    
    /**
     * 查询用户订单列表
     */
    public List<OrderResponse> getUserOrders(Long userId) {
        log.info("查询用户订单: userId={}", userId);
        List<Order> orders = orderRepository.findByUserId(userId);
        return orders.stream().map(this::toResponse).collect(Collectors.toList());
    }
    
    private String generateOrderNo() {
        return "ORD" + System.currentTimeMillis() + UUID.randomUUID().toString().substring(0, 8);
    }
    
    private OrderResponse toResponse(Order order) {
        OrderResponse response = new OrderResponse();
        response.setOrderNo(order.getOrderNo());
        response.setUserId(order.getUserId());
        response.setProductId(order.getProductId());
        response.setProductName(order.getProductName());
        response.setQuantity(order.getQuantity());
        response.setTotalAmount(order.getTotalAmount());
        response.setStatus(order.getStatus());
        response.setCreateTime(order.getCreateTime());
        return response;
    }
}
```

#### 实体类和DTO

```java
// Order.java
package com.demo.order.entity;

import lombok.Data;
import javax.persistence.*;
import java.math.BigDecimal;
import java.time.LocalDateTime;

@Data
@Entity
@Table(name = "t_order")
public class Order {
    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    private Long id;
    
    @Column(unique = true, nullable = false)
    private String orderNo;
    
    private Long userId;
    private Long productId;
    private String productName;
    private Integer quantity;
    private BigDecimal totalAmount;
    private String status;
    private LocalDateTime createTime;
    private LocalDateTime updateTime;
}

// OrderRequest.java
package com.demo.order.dto;

import lombok.Data;
import java.math.BigDecimal;

@Data
public class OrderRequest {
    private Long userId;
    private Long productId;
    private String productName;
    private Integer quantity;
    private BigDecimal totalAmount;
}

// OrderResponse.java
package com.demo.order.dto;

import lombok.Data;
import java.math.BigDecimal;
import java.time.LocalDateTime;

@Data
public class OrderResponse {
    private String orderNo;
    private Long userId;
    private Long productId;
    private String productName;
    private Integer quantity;
    private BigDecimal totalAmount;
    private String status;
    private LocalDateTime createTime;
}

// OrderRepository.java
package com.demo.order.repository;

import com.demo.order.entity.Order;
import org.springframework.data.jpa.repository.JpaRepository;
import java.util.List;
import java.util.Optional;

public interface OrderRepository extends JpaRepository<Order, Long> {
    Optional<Order> findByOrderNo(String orderNo);
    List<Order> findByUserId(Long userId);
}
```

#### 启动类

```java
package com.demo.order;

import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.cloud.client.discovery.EnableDiscoveryClient;

@SpringBootApplication
@EnableDiscoveryClient
public class OrderServiceApplication {
    public static void main(String[] args) {
        SpringApplication.run(OrderServiceApplication.class, args);
    }
}
```

### 4.4 库存服务 (inventory-service)

#### bootstrap.yml（Nacos配置中心需要）

```yaml
spring:
  application:
    name: inventory-service
  cloud:
    nacos:
      config:
        server-addr: 192.168.xxx.xxx:8848
        file-extension: yaml
        namespace: public
      discovery:
        server-addr: 192.168.xxx.xxx:8848
```

#### application.yml

```yaml
server:
  port: 8082

spring:
  application:
    name: inventory-service
  
  datasource:
    url: jdbc:postgresql://192.168.xxx.xxx:5432/order_db
    username: admin
    password: Admin@123
    driver-class-name: org.postgresql.Driver
  
  jpa:
    hibernate:
      ddl-auto: update
    show-sql: true
  
  redis:
    host: 192.168.xxx.xxx
    port: 6379
    password: redis
  
  # Kafka消费者配置
  kafka:
    bootstrap-servers: 192.168.xxx.xxx:9092
    consumer:
      group-id: inventory-service-group
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer
      properties:
        spring.json.trusted.packages: '*'
      auto-offset-reset: earliest
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer
  
  # RabbitMQ配置
  rabbitmq:
    host: 192.168.xxx.xxx
    port: 5672
    username: admin
    password: Admin@123

management:
  endpoints:
    web:
      exposure:
        include: '*'
  metrics:
    export:
      prometheus:
        enabled: true
```

#### InventoryService.java

```java
package com.demo.inventory.service;

import com.demo.inventory.entity.Inventory;
import com.demo.inventory.repository.InventoryRepository;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.amqp.rabbit.core.RabbitTemplate;
import org.springframework.data.redis.core.StringRedisTemplate;
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.stereotype.Service;
import org.springframework.transaction.annotation.Transactional;

import java.util.Map;

@Slf4j
@Service
@RequiredArgsConstructor
public class InventoryService {
    
    private final InventoryRepository inventoryRepository;
    private final RabbitTemplate rabbitTemplate;
    private final StringRedisTemplate redisTemplate;
    
    /**
     * 监听Kafka订单创建消息
     */
    @KafkaListener(topics = "order-created", groupId = "inventory-service-group")
    @Transactional
    public void handleOrderCreated(Map<String, Object> orderData) {
        log.info("收到订单创建消息: {}", orderData);
        
        try {
            Long productId = Long.valueOf(orderData.get("productId").toString());
            Integer quantity = Integer.valueOf(orderData.get("quantity").toString());
            String orderNo = orderData.get("orderNo").toString();
            
            // 扣减库存
            boolean success = deductInventory(productId, quantity);
            
            if (success) {
                log.info("库存扣减成功: productId={}, quantity={}", productId, quantity);
                
                // 发送RabbitMQ通知消息
                Map<String, Object> notification = Map.of(
                    "orderNo", orderNo,
                    "productId", productId,
                    "type", "INVENTORY_DEDUCTED",
                    "message", "库存扣减成功"
                );
                rabbitTemplate.convertAndSend("order.exchange", "notification.order", notification);
                log.info("已发送RabbitMQ通知: {}", orderNo);
            } else {
                log.error("库存不足: productId={}, quantity={}", productId, quantity);
            }
        } catch (Exception e) {
            log.error("处理订单消息失败", e);
        }
    }
    
    /**
     * 扣减库存 (乐观锁)
     */
    @Transactional
    public boolean deductInventory(Long productId, Integer quantity) {
        Inventory inventory = inventoryRepository.findByProductId(productId)
                .orElseThrow(() -> new RuntimeException("商品不存在"));
        
        if (inventory.getStock() < quantity) {
            return false;
        }
        
        inventory.setStock(inventory.getStock() - quantity);
        inventory.setVersion(inventory.getVersion() + 1);
        inventoryRepository.save(inventory);
        
        // 更新Redis缓存
        String cacheKey = "inventory:" + productId;
        redisTemplate.opsForValue().set(cacheKey, String.valueOf(inventory.getStock()));
        
        return true;
    }
    
    /**
     * 查询库存
     */
    public Integer getStock(Long productId) {
        // 先查Redis
        String cacheKey = "inventory:" + productId;
        String cached = redisTemplate.opsForValue().get(cacheKey);
        if (cached != null) {
            return Integer.valueOf(cached);
        }
        
        // 查数据库
        Inventory inventory = inventoryRepository.findByProductId(productId)
                .orElseThrow(() -> new RuntimeException("商品不存在"));
        
        // 写回Redis
        redisTemplate.opsForValue().set(cacheKey, String.valueOf(inventory.getStock()));
        
        return inventory.getStock();
    }
}
```

### 4.5 通知服务 (notification-service)

#### bootstrap.yml（Nacos配置中心需要）

```yaml
spring:
  application:
    name: notification-service
  cloud:
    nacos:
      config:
        server-addr: 192.168.xxx.xxx:8848
        file-extension: yaml
        namespace: public
      discovery:
        server-addr: 192.168.xxx.xxx:8848
```

#### application.yml

```yaml
server:
  port: 8083

spring:
  application:
    name: notification-service
  
  # RabbitMQ配置
  rabbitmq:
    host: 192.168.xxx.xxx
    port: 5672
    username: admin
    password: Admin@123

management:
  endpoints:
    web:
      exposure:
        include: '*'
  metrics:
    export:
      prometheus:
        enabled: true
```

#### NotificationService.java

```java
package com.demo.notification.service;

import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.amqp.rabbit.annotation.RabbitListener;
import org.springframework.stereotype.Service;

import java.util.Map;

@Slf4j
@Service
@RequiredArgsConstructor
public class NotificationService {
    
    /**
     * 监听RabbitMQ通知消息
     */
    @RabbitListener(queues = "notification.queue")
    public void handleNotification(Map<String, Object> message) {
        log.info("=== 收到通知消息 ===");
        log.info("订单号: {}", message.get("orderNo"));
        log.info("类型: {}", message.get("type"));
        log.info("消息: {}", message.get("message"));
        log.info("==================");
        
        // 实际应用中可以发送短信、邮件、推送等
        sendSms(message);
        sendEmail(message);
    }
    
    private void sendSms(Map<String, Object> message) {
        log.info("[短信通知] 订单 {} 处理完成", message.get("orderNo"));
    }
    
    private void sendEmail(Map<String, Object> message) {
        log.info("[邮件通知] 订单 {} 处理完成", message.get("orderNo"));
    }
}
```

### 4.6 API网关 (gateway-service)

API 网关是微服务架构的统一入口，负责路由、负载均衡、跨域处理等功能。

#### 4.6.1 创建网关服务

在父 POM 中添加模块：
```xml
<modules>
    <module>common</module>
    <module>order-service</module>
    <module>inventory-service</module>
    <module>notification-service</module>
    <module>gateway-service</module>
</modules>
```

#### 4.6.2 网关 POM 配置

`gateway-service/pom.xml`:

```xml
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 
         http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <parent>
        <groupId>com.demo</groupId>
        <artifactId>ecommerce-microservices</artifactId>
        <version>1.0.0</version>
    </parent>
    <modelVersion>4.0.0</modelVersion>
    <artifactId>gateway-service</artifactId>

    <dependencies>
        <!-- Spring Cloud Gateway -->
        <dependency>
            <groupId>org.springframework.cloud</groupId>
            <artifactId>spring-cloud-starter-gateway</artifactId>
        </dependency>

        <!-- Nacos Discovery -->
        <dependency>
            <groupId>com.alibaba.cloud</groupId>
            <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>
        </dependency>

        <!-- Nacos Config -->
        <dependency>
            <groupId>com.alibaba.cloud</groupId>
            <artifactId>spring-cloud-starter-alibaba-nacos-config</artifactId>
        </dependency>
        
        <!-- Actuator (监控) -->
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-actuator</artifactId>
        </dependency>

        <!-- Lombok -->
        <dependency>
            <groupId>org.projectlombok</groupId>
            <artifactId>lombok</artifactId>
        </dependency>
    </dependencies>
</project>
```

#### 4.6.3 bootstrap.yml（Nacos配置中心需要）

```yaml
spring:
  application:
    name: gateway-service
  cloud:
    nacos:
      config:
        server-addr: 192.168.xxx.xxx:8848
        file-extension: yaml
        namespace: public
      discovery:
        server-addr: 192.168.xxx.xxx:8848
```

#### 4.6.4 application.yml

```yaml
server:
  port: 8000

spring:
  application:
    name: gateway-service
  
  cloud:
    nacos:
      discovery:
        server-addr: 192.168.xxx.xxx:8848
    
    gateway:
      # 路由配置
      routes:
        # 订单服务路由
        - id: order-service
          uri: lb://order-service  # lb表示负载均衡，从Nacos获取服务地址
          predicates:
            - Path=/api/orders/**  # 匹配路径
          filters:
            - StripPrefix=0  # 不去除路径前缀
        
        # 库存服务路由
        - id: inventory-service
          uri: lb://inventory-service
          predicates:
            - Path=/api/inventory/**
        
        # 通知服务路由
        - id: notification-service
          uri: lb://notification-service
          predicates:
            - Path=/api/notifications/**
      
      # 全局跨域配置
      globalcors:
        cors-configurations:
          '[/**]':
            allowed-origins: "*"  # 允许所有域名（生产环境需要指定具体域名）
            allowed-methods: "*"  # 允许所有HTTP方法
            allowed-headers: "*"  # 允许所有请求头
            allow-credentials: true  # 允许携带cookie
      
      # 发现定位器配置（自动从Nacos发现服务）
      discovery:
        locator:
          enabled: true  # 开启服务发现
          lower-case-service-id: true  # 服务名转小写

management:
  endpoints:
    web:
      exposure:
        include: '*'
  metrics:
    export:
      prometheus:
        enabled: true
```

#### 4.6.5 网关启动类

`gateway-service/src/main/java/com/demo/gateway/GatewayServiceApplication.java`:

```java
package com.demo.gateway;

import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.cloud.client.discovery.EnableDiscoveryClient;

/**
 * API 网关服务
 * 
 * 功能说明：
 * 1. 统一入口：所有外部请求通过网关访问微服务
 * 2. 路由转发：根据请求路径转发到对应的微服务
 * 3. 负载均衡：使用 Ribbon 对多实例服务进行负载均衡
 * 4. 跨域处理：统一处理 CORS 跨域问题
 * 5. 服务发现：从 Nacos 自动发现服务实例
 * 
 * 技术栈：
 * - Spring Cloud Gateway: 响应式网关框架
 * - Nacos: 服务注册与发现
 * - Ribbon: 客户端负载均衡
 */
@SpringBootApplication
@EnableDiscoveryClient
public class GatewayServiceApplication {
    public static void main(String[] args) {
        SpringApplication.run(GatewayServiceApplication.class, args);
    }
}
```

#### 4.6.6 编译打包网关

```bash
# 编译网关服务
cd ~/ecommerce-microservices
mvn clean package -pl gateway-service -am -DskipTests

# 查看生成的jar包
ls -lh gateway-service/target/*.jar
```

#### 4.6.7 启动网关服务

```bash
# 普通启动
java -jar gateway-service/target/gateway-service-1.0.0.jar

# 使用 SkyWalking Agent 启动（如果配置了）
export SW_AGENT_HOME=~/docker-env/skywalking/skywalking-agent

java -javaagent:${SW_AGENT_HOME}/skywalking-agent.jar \
  -Dskywalking.agent.service_name=gateway-service \
  -Dskywalking.collector.backend_service=192.168.xxx.xxx:11800 \
  -jar gateway-service/target/gateway-service-1.0.0.jar &
```

#### 4.6.8 验证网关

```bash
# 1. 检查网关是否注册到 Nacos
curl http://192.168.xxx.xxx:8848/nacos/v1/ns/instance/list?serviceName=gateway-service

# 2. 通过网关访问订单服务
curl http://192.168.xxx.xxx:8000/api/orders/health

# 3. 通过网关创建订单
curl -X POST http://192.168.xxx.xxx:8000/api/orders \
  -H "Content-Type: application/json" \
  -d '{
    "userId": 1001,
    "productId": 1001,
    "productName": "iPhone 15 Pro",
    "quantity": 2,
    "totalAmount": 16998.00
  }'

# 4. 通过网关查询订单
curl http://192.168.xxx.xxx:8000/api/orders/user/1001
```

---

## 第五部分：前端部署

### 5.1 前端项目说明

项目已包含基于 Vue 3 + TypeScript + Vite + Element Plus 的现代化前端。

**前端功能**：
- ✅ 创建订单
- ✅ 订单列表查询
- ✅ 订单详情查看
- ✅ 状态追踪展示

### 5.2 安装 Node.js

```bash
# 使用 NodeSource 仓库安装 Node.js 16
curl -fsSL https://rpm.nodesource.com/setup_16.x | sudo bash -
sudo yum install -y nodejs

# 验证安装
node -v   # 应显示 v16.x.x
npm -v    # 应显示 8.x.x

# 或者安装 pnpm（推荐，更快）
npm install -g pnpm
pnpm -v
```

### 5.3 配置前端环境

```bash
# 进入前端目录
cd ~/ecommerce-microservices/frontend

# 查看项目结构
ls -l
# 应该看到：
# - package.json
# - vite.config.ts
# - src/
# - index.html
```

### 5.4 修改网关地址

编辑 `frontend/vite.config.ts`，确保代理地址正确：

```typescript
export default defineConfig({
  plugins: [vue()],
  
  server: {
    port: 3000,
    host: '0.0.0.0',
    open: true,
    proxy: {
      '/api': {
        target: 'http://192.168.xxx.xxx:8000', // 改为你的虚拟机IP
        changeOrigin: true
      }
    }
  }
})
```

### 5.5 安装依赖并启动

```bash
# 方式一：使用 npm
cd ~/ecommerce-microservices/frontend
npm install

# 启动开发服务器
npm run dev

# 方式二：使用 pnpm（推荐）
cd ~/ecommerce-microservices/frontend
pnpm install

# 启动开发服务器
pnpm dev
```

### 5.6 访问前端

```bash
# 在虚拟机中启动后，会显示：
# ➜  Local:   http://localhost:3000/
# ➜  Network: http://192.168.xxx.xxx:3000/

# 从宿主机浏览器访问：
http://192.168.xxx.xxx:3000
```

### 5.7 构建生产版本

```bash
# 构建生产版本
cd ~/ecommerce-microservices/frontend
npm run build
# 或
pnpm build

# 构建产物在 dist/ 目录
ls -lh dist/
```

### 5.8 使用 Nginx 部署前端（生产环境推荐 ✅）

#### 5.8.1 为什么使用 Nginx？

**性能对比：**
| 指标 | Node.js serve | Spring Boot | Nginx |
|------|--------------|-------------|-------|
| QPS（请求/秒） | 8,000 | 3,245 | **52,189** ✅ |
| 响应时间 | 12 ms | 30.8 ms | **1.9 ms** ✅ |
| 内存占用 | 80 MB | 450 MB | **15 MB** ✅ |

**核心优势：**
- ✅ 专为静态资源优化，性能是Java的16倍
- ✅ Gzip压缩，节省74%带宽
- ✅ 浏览器缓存，加载速度提升8倍
- ✅ 反向代理，统一访问入口
- ✅ SSL终止，保护数据安全

#### 5.8.2 安装 Nginx

```bash
# CentOS/Rocky Linux
sudo yum install -y nginx

# Ubuntu/Debian
sudo apt install -y nginx

# 验证安装
nginx -v
# 输出：nginx version: nginx/1.20.1
```

#### 5.8.3 部署前端静态文件

```bash
# 1. 确保前端已构建
cd ~/ecommerce-microservices/frontend
npm run build

# 2. 备份Nginx默认页面（可选）
sudo mv /usr/share/nginx/html /usr/share/nginx/html.bak

# 3. 复制构建产物到Nginx目录
sudo mkdir -p /usr/share/nginx/html
sudo cp -r dist/* /usr/share/nginx/html/

# 4. 设置权限
sudo chown -R nginx:nginx /usr/share/nginx/html
sudo chmod -R 755 /usr/share/nginx/html

# 5. 验证文件
ls -lh /usr/share/nginx/html/
# 应该看到：index.html, assets/, favicon.ico 等
```

#### 5.8.4 Nginx 完整配置（包含性能优化）

创建配置文件：

```bash
sudo vi /etc/nginx/conf.d/ecommerce.conf
```

配置内容（**生产级配置**）：

```nginx
# ============================================
# 电商微服务前端 Nginx 配置
# 功能：静态资源服务 + API反向代理 + 性能优化
# ============================================

# 限流配置（防DDoS）
limit_req_zone $binary_remote_addr zone=api_limit:10m rate=10r/s;

server {
    listen 80;
    server_name localhost;  # 生产环境替换为实际域名
    
    # 访问日志
    access_log /var/log/nginx/ecommerce_access.log;
    error_log /var/log/nginx/ecommerce_error.log warn;
    
    # ============================================
    # 前端静态资源
    # ============================================
    location / {
        root /usr/share/nginx/html;
        index index.html;
        
        # SPA 路由支持（Vue Router History模式）
        try_files $uri $uri/ /index.html;
        
        # HTML 文件：不缓存（确保及时更新）
        location ~* \.html$ {
            expires -1;
            add_header Cache-Control "no-cache, no-store, must-revalidate";
        }
        
        # JS/CSS 文件：强缓存1年（文件名带hash）
        location ~* \.(js|css)$ {
            expires 1y;
            add_header Cache-Control "public, immutable";
        }
        
        # 图片文件：缓存1个月
        location ~* \.(jpg|jpeg|png|gif|ico|svg|webp)$ {
            expires 30d;
            add_header Cache-Control "public";
        }
        
        # 字体文件：缓存1年
        location ~* \.(woff|woff2|ttf|eot)$ {
            expires 1y;
            add_header Cache-Control "public";
            # 字体跨域支持
            add_header Access-Control-Allow-Origin *;
        }
    }
    
    # ============================================
    # API 反向代理到 Gateway
    # ============================================
    location /api/ {
        # 限流：每秒最多10次请求，突发允许20次
        limit_req zone=api_limit burst=20 nodelay;
        
        # 代理到 Gateway
        proxy_pass http://localhost:8000;
        
        # 请求头配置
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # 超时配置
        proxy_connect_timeout 10s;
        proxy_send_timeout 60s;
        proxy_read_timeout 60s;
        
        # WebSocket 支持（如果需要）
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
    }
    
    # ============================================
    # 健康检查端点
    # ============================================
    location /health {
        access_log off;
        return 200 "healthy\n";
        add_header Content-Type text/plain;
    }
}
```

#### 5.8.5 启用 Gzip 压缩（关键优化！）

编辑主配置文件：

```bash
sudo vi /etc/nginx/nginx.conf
```

在 `http` 块中添加 Gzip 配置：

```nginx
http {
    # ... 其他配置 ...
    
    # ============================================
    # Gzip 压缩配置（节省74%带宽）
    # ============================================
    gzip on;                    # 启用压缩
    gzip_vary on;               # 添加 Vary: Accept-Encoding
    gzip_comp_level 6;          # 压缩级别（1-9）
    gzip_min_length 1000;       # 小于1KB不压缩
    gzip_proxied any;           # 对所有代理请求启用压缩
    gzip_types
        text/plain
        text/css
        text/xml
        text/javascript
        application/json
        application/javascript
        application/xml+rss
        application/rss+xml
        font/truetype
        font/opentype
        application/vnd.ms-fontobject
        image/svg+xml;
    gzip_disable "msie6";       # 禁用IE6压缩
    
    # ... 其他配置 ...
}
```

**Gzip 压缩效果：**
```
压缩前：1,404 KB
压缩后：365 KB
节省：74% ✅

加载时间：
- 4G网络：从 0.28秒 → 0.07秒（快4倍）
- 3G网络：从 1.4秒 → 0.37秒（快3.8倍）
```

#### 5.8.6 测试和启动 Nginx

```bash
# 1. 测试配置文件语法
sudo nginx -t
# 输出应该显示：
# nginx: configuration file /etc/nginx/nginx.conf test is successful

# 2. 启动 Nginx
sudo systemctl start nginx
sudo systemctl enable nginx

# 3. 检查状态
sudo systemctl status nginx

# 4. 查看监听端口
sudo netstat -tlnp | grep nginx
# 应该看到：0.0.0.0:80

# 5. 测试访问
curl -I http://localhost
# 应该返回 200 OK
```

#### 5.8.7 验证优化效果

##### 验证 Gzip 压缩

```bash
# 检查响应头
curl -I -H "Accept-Encoding: gzip" http://localhost/assets/index.js

# 应该看到：
# Content-Encoding: gzip ✅
# Vary: Accept-Encoding ✅
```

##### 验证缓存

```bash
# 检查 JS 文件缓存
curl -I http://localhost/assets/index-abc123.js

# 应该看到：
# Cache-Control: public, immutable ✅
# Expires: (1年后的日期) ✅

# 检查 HTML 文件不缓存
curl -I http://localhost/

# 应该看到：
# Cache-Control: no-cache, no-store, must-revalidate ✅
```

##### 验证反向代理

```bash
# 测试 API 代理
curl http://localhost/api/orders

# 应该返回订单数据（通过网关转发）
```

#### 5.8.8 性能测试对比

使用 Apache Bench 测试：

```bash
# 安装测试工具
sudo yum install -y httpd-tools

# 测试前端首页性能
ab -n 1000 -c 100 http://localhost/

# 关键指标：
# - Requests per second: 应该 > 10,000
# - Time per request: 应该 < 10ms
```

**预期结果：**
```
Document Path:          /
Concurrency Level:      100
Complete requests:      1000
Time taken for tests:   0.192 seconds
Requests per second:    52,189 [#/sec] ✅
Time per request:       1.9 [ms] ✅
Transfer rate:          410,000 [KB/sec] ✅
```

#### 5.8.9 常用管理命令

```bash
# 重新加载配置（不停机）
sudo systemctl reload nginx

# 重启 Nginx
sudo systemctl restart nginx

# 查看错误日志
sudo tail -f /var/log/nginx/ecommerce_error.log

# 查看访问日志
sudo tail -f /var/log/nginx/ecommerce_access.log

# 测试配置文件
sudo nginx -t

# 查看 Nginx 进程
ps aux | grep nginx
```

#### 5.8.10 生产环境 HTTPS 配置（可选）

如果有 SSL 证书，可以启用 HTTPS：

```nginx
# HTTP 自动跳转 HTTPS
server {
    listen 80;
    server_name your-domain.com;
    return 301 https://$server_name$request_uri;
}

# HTTPS 配置
server {
    listen 443 ssl http2;
    server_name your-domain.com;
    
    # SSL 证书
    ssl_certificate /etc/nginx/ssl/your-domain.crt;
    ssl_certificate_key /etc/nginx/ssl/your-domain.key;
    
    # SSL 安全配置
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers HIGH:!aNULL:!MD5;
    ssl_prefer_server_ciphers on;
    
    # HSTS（强制HTTPS）
    add_header Strict-Transport-Security "max-age=31536000" always;
    
    # ... 其他location配置同上 ...
}
```

#### 5.8.11 Docker 方式部署 Nginx（推荐）

如果使用 Docker，可以更简单：

```yaml
# docker-compose.yml 中添加
services:
  nginx:
    image: nginx:1.25-alpine
    container_name: ecommerce-nginx
    ports:
      - "80:80"
    volumes:
      - ./frontend/dist:/usr/share/nginx/html:ro
      - ./nginx/ecommerce.conf:/etc/nginx/conf.d/default.conf:ro
    depends_on:
      - gateway
    restart: unless-stopped
```

```bash
# 启动
docker-compose up -d nginx

# 查看日志
docker-compose logs -f nginx
```

#### 5.8.12 优化总结

| 优化项 | 效果 | 配置难度 |
|--------|------|---------|
| **Nginx 静态服务** | 性能提升16倍 | ⭐ 简单 |
| **Gzip 压缩** | 节省74%带宽 | ⭐ 简单 |
| **浏览器缓存** | 加载速度快8倍 | ⭐ 简单 |
| **反向代理** | 统一访问入口 | ⭐ 简单 |
| **限流保护** | 防DDoS攻击 | ⭐⭐ 中等 |
| **HTTPS** | 数据安全 | ⭐⭐ 中等 |

**架构图：**
```
用户浏览器
    │
    ▼
┌─────────────────────┐
│   Nginx (:80)       │
│  ✅ 静态资源         │  ← 性能16倍提升
│  ✅ Gzip压缩         │  ← 节省74%带宽
│  ✅ 浏览器缓存       │  ← 加载快8倍
│  ✅ API代理          │  ← 统一入口
└─────┬───────────────┘
      │
      │ /api/* 请求
      ▼
┌─────────────────────┐
│  Gateway (:8000)    │
│  ✅ 动态路由         │
│  ✅ 服务发现         │
│  ✅ 业务鉴权         │
└─────┬───────────────┘
      │
   微服务集群
```

---

## 第六部分：应用部署与测试

### 6.1 编译打包后端服务

```bash
# 在项目根目录执行
cd ~/ecommerce-microservices
mvn clean package -DskipTests

# 查看生成的jar包
ls -lh order-service/target/*.jar
ls -lh inventory-service/target/*.jar
ls -lh notification-service/target/*.jar
ls -lh gateway-service/target/*.jar
```

### 6.2 使用SkyWalking Agent启动服务

```bash
# 设置SkyWalking Agent路径
export SW_AGENT_HOME=~/docker-env/skywalking/skywalking-agent

# 启动订单服务
java -javaagent:${SW_AGENT_HOME}/skywalking-agent.jar \
  -Dskywalking.agent.service_name=order-service \
  -Dskywalking.collector.backend_service=192.168.xxx.xxx:11800 \
  -jar order-service/target/order-service-1.0.0.jar &

# 启动库存服务
java -javaagent:${SW_AGENT_HOME}/skywalking-agent.jar \
  -Dskywalking.agent.service_name=inventory-service \
  -Dskywalking.collector.backend_service=192.168.xxx.xxx:11800 \
  -jar inventory-service/target/inventory-service-1.0.0.jar &

# 启动通知服务
java -javaagent:${SW_AGENT_HOME}/skywalking-agent.jar \
  -Dskywalking.agent.service_name=notification-service \
  -Dskywalking.collector.backend_service=192.168.xxx.xxx:11800 \
  -jar notification-service/target/notification-service-1.0.0.jar &

# 启动网关服务
java -javaagent:${SW_AGENT_HOME}/skywalking-agent.jar \
  -Dskywalking.agent.service_name=gateway-service \
  -Dskywalking.collector.backend_service=192.168.xxx.xxx:11800 \
  -jar gateway-service/target/gateway-service-1.0.0.jar &
```

### 6.3 功能测试

```bash
# 1. 测试创建订单
curl -X POST http://192.168.xxx.xxx:8000/api/orders \
  -H "Content-Type: application/json" \
  -d '{
    "userId": 1001,
    "productId": 1001,
    "productName": "iPhone 15 Pro",
    "quantity": 2,
    "totalAmount": 16998.00
  }'

# 2. 查询订单
curl http://192.168.xxx.xxx:8000/api/orders/ORD1234567890abcdefgh

# 3. 查询用户订单
curl http://192.168.xxx.xxx:8000/api/orders/user/1001

# 4. 查询库存
curl http://192.168.xxx.xxx:8082/api/inventory/1001
```

### 6.4 通过前端测试（推荐）

访问前端页面进行可视化测试：

#### 6.4.1 创建订单
1. 打开浏览器访问 `http://192.168.xxx.xxx:3000`
2. 点击顶部导航栏的 "创建订单"
3. 填写订单信息：
   - 用户ID: 1001
   - 商品ID: 1001  
   - 商品名称: iPhone 15 Pro
   - 购买数量: 2
   - 订单金额: 16998.00
4. 点击 "提交订单"
5. 系统会自动跳转到订单详情页

#### 6.4.2 查看订单列表
1. 点击顶部导航栏的 "订单列表"
2. 输入用户ID: 1001
3. 点击 "查询" 按钮
4. 查看该用户的所有订单

#### 6.4.3 查看订单详情
1. 在订单列表中点击某个订单的 "查看详情"
2. 查看订单完整信息
3. 查看处理流程（订单创建 → 库存扣减 → 发送通知 → 订单完成）

#### 6.4.4 观察后端日志
在后端服务日志中观察业务流程：

```bash
# 订单服务日志
tail -f ~/ecommerce-microservices/logs/order-service.log

# 库存服务日志  
tail -f ~/ecommerce-microservices/logs/inventory-service.log

# 通知服务日志
tail -f ~/ecommerce-microservices/logs/notification-service.log
```

### 6.5 监控查看

1. **Nacos控制台**: `http://虚拟机IP:8848/nacos`
   - 查看服务注册情况

2. **SkyWalking UI**: `http://虚拟机IP:8080`
   - 查看链路追踪
   - 服务拓扑图
   - 性能指标

3. **Grafana**: `http://虚拟机IP:3000`
   - 添加Prometheus数据源: `http://prometheus:9091`
   - 导入JVM监控面板 (ID: 4701)
   - 导入Spring Boot监控面板 (ID: 12900)

4. **Prometheus**: `http://虚拟机IP:9091`
   - 查看Targets状态
   - 执行PromQL查询

5. **RabbitMQ管理界面**: `http://虚拟机IP:15672`
   - 查看队列消息

---

## 第六部分：Kubernetes部署 (可选进阶)

### 6.1 安装K8s (使用K3s轻量版)

```bash
# 安装K3s (单节点)
curl -sfL https://get.k3s.io | sh -

# 配置kubectl
sudo cp /etc/rancher/k3s/k3s.yaml ~/.kube/config
sudo chown $USER ~/.kube/config

# 验证
kubectl get nodes
kubectl get pods -A
```

### 6.2 创建Deployment

```yaml
# order-service-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: order-service
spec:
  replicas: 2
  selector:
    matchLabels:
      app: order-service
  template:
    metadata:
      labels:
        app: order-service
    spec:
      containers:
      - name: order-service
        image: order-service:1.0.0
        ports:
        - containerPort: 8081
        env:
        - name: SPRING_PROFILES_ACTIVE
          value: k8s
---
apiVersion: v1
kind: Service
metadata:
  name: order-service
spec:
  selector:
    app: order-service
  ports:
  - protocol: TCP
    port: 8081
    targetPort: 8081
  type: ClusterIP
```

```bash
# 部署到K8s
kubectl apply -f order-service-deployment.yaml

# 查看部署状态
kubectl get pods
kubectl get svc
```

---

## 第七部分：Jenkins CI/CD配置

### 7.1 安装Jenkins

```bash
# 使用Docker运行Jenkins
docker run -d \
  --name jenkins \
  -p 8090:8080 \
  -p 50000:50000 \
  -v ~/docker-env/jenkins/home:/var/jenkins_home \
  -v /var/run/docker.sock:/var/run/docker.sock \
  --restart=always \
  jenkins/jenkins:lts

# 获取初始密码
docker exec jenkins cat /var/jenkins_home/secrets/initialAdminPassword

# 访问Jenkins: http://虚拟机IP:8090
```

### 7.2 创建Pipeline

```groovy
// Jenkinsfile
pipeline {
    agent any
    
    stages {
        stage('拉取代码') {
            steps {
                git branch: 'main', url: 'https://github.com/your-repo/ecommerce-microservices.git'
            }
        }
        
        stage('Maven编译') {
            steps {
                sh 'mvn clean package -DskipTests'
            }
        }
        
        stage('构建Docker镜像') {
            steps {
                sh '''
                    docker build -t order-service:${BUILD_NUMBER} ./order-service
                    docker build -t inventory-service:${BUILD_NUMBER} ./inventory-service
                    docker build -t notification-service:${BUILD_NUMBER} ./notification-service
                '''
            }
        }
        
        stage('部署到K8s') {
            steps {
                sh '''
                    kubectl set image deployment/order-service \
                        order-service=order-service:${BUILD_NUMBER}
                    kubectl rollout status deployment/order-service
                '''
            }
        }
    }
    
    post {
        success {
            echo '部署成功!'
        }
        failure {
            echo '部署失败!'
        }
    }
}
```

---

## 第八部分：压力测试与性能优化

### 8.1 使用JMeter压测

```bash
# 安装JMeter
cd /opt
wget https://dlcdn.apache.org/jmeter/binaries/apache-jmeter-5.6.2.tgz
tar -zxvf apache-jmeter-5.6.2.tgz

# 启动JMeter GUI
./apache-jmeter-5.6.2/bin/jmeter.sh

# 创建测试计划
# - 添加线程组: 100并发用户
# - 添加HTTP请求: POST http://192.168.xxx.xxx:8000/api/orders
# - 添加监听器: 聚合报告、查看结果树

# 命令行运行压测
./jmeter -n -t test-plan.jmx -l result.jtl -e -o report
```

### 8.2 性能优化点

1. **数据库优化**
   - 添加索引
   - 使用连接池
   - 读写分离

2. **缓存优化**
   - Redis缓存热点数据
   - 本地缓存(Caffeine)

3. **异步处理**
   - Kafka异步解耦
   - @Async异步方法

4. **限流降级**
   - Sentinel流控
   - Hystrix熔断

---

## 第九部分：常见问题排查

### 9.1 服务无法启动

```bash
# 查看日志
docker logs -f <container_name>

# 查看端口占用
netstat -tunlp | grep <port>

# 检查防火墙
systemctl status firewalld
```

### 9.2 服务间调用失败

```bash
# 检查Nacos注册
curl http://192.168.xxx.xxx:8848/nacos/v1/ns/instance/list?serviceName=order-service

# 检查网络连通性
ping <service_ip>
telnet <service_ip> <port>

# 查看SkyWalking链路
# 访问SkyWalking UI查看调用链
```

### 9.3 消息消费失败

```bash
# Kafka查看消费者组
docker exec -it kafka kafka-consumer-groups \
  --bootstrap-server localhost:9093 \
  --describe --group inventory-service-group

# RabbitMQ查看队列
# 访问管理界面 http://虚拟机IP:15672
```

---

## 第十部分：学习路线与面试准备

### 10.1 技术点总结

| 技术 | 掌握程度 | 项目中的应用 |
|------|---------|------------|
| PostgreSQL | ⭐⭐⭐ | 主数据库,存储订单和库存数据 |
| Redis | ⭐⭐⭐ | 缓存热点数据,提升查询性能 |
| Kafka | ⭐⭐⭐ | 订单创建消息,异步解耦 |
| RabbitMQ | ⭐⭐⭐ | 通知消息,可靠消息传递 |
| Nacos | ⭐⭐⭐ | 服务注册发现,配置中心 |
| Docker | ⭐⭐⭐⭐ | 容器化部署所有中间件 |
| K8s | ⭐⭐ | 容器编排,服务扩缩容 |
| Jenkins | ⭐⭐⭐ | CI/CD自动化部署 |
| SkyWalking | ⭐⭐⭐ | 链路追踪,性能分析 |
| Grafana | ⭐⭐⭐ | 监控可视化 |

### 10.2 面试话术参考

**面试官**: "介绍一下你的项目"

**回答**: 
"我做了一个电商订单管理系统,采用Spring Cloud微服务架构。系统包含订单服务、库存服务、通知服务三个核心微服务,通过Nacos实现服务注册发现。

技术栈方面:
- 使用PostgreSQL作为主数据库,存储订单和库存数据
- 使用Redis缓存热点商品库存,提升查询性能
- 通过Kafka实现订单创建的异步消息通知
- 使用RabbitMQ处理通知类消息
- 整个系统通过Docker容器化部署
- 使用SkyWalking做全链路追踪
- 通过Grafana+Prometheus实现系统监控
- Jenkins实现CI/CD自动化部署

在这个项目中,我深入实践了分布式系统的设计,包括服务拆分、异步消息、缓存优化、链路追踪等核心技术点。"

### 10.3 深入学习建议

1. **PostgreSQL**
   - 索引优化
   - 执行计划分析
   - 主从复制

2. **Redis**
   - 数据结构应用场景
   - 持久化机制
   - 集群方案

3. **Kafka**
   - 分区策略
   - 消费者组
   - 消息可靠性

4. **K8s**
   - Pod、Service、Deployment
   - ConfigMap、Secret
   - Ingress

---

## 附录：快速启动脚本

### start-all.sh

```bash
#!/bin/bash

echo "=== 启动所有Docker容器 ==="

# 基础服务
docker start postgres redis rabbitmq nacos

# Kafka
cd ~/docker-env/kafka && docker-compose start

# 监控服务
cd ~/docker-env/monitor && docker-compose start

# SkyWalking
cd ~/docker-env/skywalking && docker-compose start

echo "=== 等待服务启动 ==="
sleep 30

echo "=== 启动微服务 ==="
cd ~/ecommerce-microservices

# 启动订单服务
java -javaagent:~/docker-env/skywalking/skywalking-agent/skywalking-agent.jar \
  -Dskywalking.agent.service_name=order-service \
  -Dskywalking.collector.backend_service=localhost:11800 \
  -jar order-service/target/order-service-1.0.0.jar \
  > logs/order-service.log 2>&1 &

# 启动库存服务
java -javaagent:~/docker-env/skywalking/skywalking-agent/skywalking-agent.jar \
  -Dskywalking.agent.service_name=inventory-service \
  -Dskywalking.collector.backend_service=localhost:11800 \
  -jar inventory-service/target/inventory-service-1.0.0.jar \
  > logs/inventory-service.log 2>&1 &

# 启动通知服务
java -javaagent:~/docker-env/skywalking/skywalking-agent/skywalking-agent.jar \
  -Dskywalking.agent.service_name=notification-service \
  -Dskywalking.collector.backend_service=localhost:11800 \
  -jar notification-service/target/notification-service-1.0.0.jar \
  > logs/notification-service.log 2>&1 &

# 启动网关
java -javaagent:~/docker-env/skywalking/skywalking-agent/skywalking-agent.jar \
  -Dskywalking.agent.service_name=gateway-service \
  -Dskywalking.collector.backend_service=localhost:11800 \
  -jar gateway-service/target/gateway-service-1.0.0.jar \
  > logs/gateway-service.log 2>&1 &

echo "=== 所有服务已启动 ==="
echo "访问地址:"
echo "  - Nacos: http://localhost:8848/nacos"
echo "  - SkyWalking: http://localhost:8080"
echo "  - Grafana: http://localhost:3000"
echo "  - RabbitMQ: http://localhost:15672"
echo "  - API Gateway: http://localhost:8000"
```

---

## 总结

通过本文档,你将从零开始搭建一个完整的Java微服务项目,涵盖:

✅ Linux虚拟机环境搭建  
✅ Docker容器化技术  
✅ PostgreSQL/Redis/Kafka/RabbitMQ/Nacos中间件  
✅ Spring Cloud微服务开发  
✅ SkyWalking链路追踪  
✅ Grafana监控可视化  
✅ Kubernetes容器编排  
✅ Jenkins CI/CD  

这个项目完全可以作为你的实战经验,在面试中详细讲解。

**祝你面试顺利! 🚀**

